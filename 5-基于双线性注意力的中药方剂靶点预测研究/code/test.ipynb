{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 22:23:11.953420: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-15 22:23:11.972099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731680591.993633   11016 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731680592.000148   11016 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 22:23:12.022466: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import argparse\n",
    "import warnings, os\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from dgllife.utils import smiles_to_bigraph, CanonicalAtomFeaturizer, CanonicalBondFeaturizer\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dgllife.model.gnn import GCN\n",
    "import dgl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指出cuda相关报错的详细信息\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTIDataset(data.Dataset):\n",
    "    def __init__(self, list_IDs, df, max_drug_nodes=290, max_len=1024):  # 添加max_protein_len参数\n",
    "        self.list_IDs = list_IDs\n",
    "        self.df = df\n",
    "        self.max_drug_nodes = max_drug_nodes\n",
    "        self.max_len = max_len  # 保存参数\n",
    "\n",
    "        self.atom_featurizer = CanonicalAtomFeaturizer()\n",
    "        self.bond_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
    "        # 先把smiles转化为双向图，然后添加自环\n",
    "        self.fc = partial(smiles_to_bigraph, add_self_loop=True)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('./prot_bert', do_lower_case=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.list_IDs[index]\n",
    "        v_d = self.df.iloc[index]['SMILES']\n",
    "        v_d = self.fc(smiles=v_d, node_featurizer=self.atom_featurizer, edge_featurizer=self.bond_featurizer)\n",
    "        # 获取实际结点特征，同时从数据结构中删去此特征\n",
    "        actual_node_feats = v_d.ndata.pop('h')\n",
    "        # 分子特征的第一个元素为原子数量\n",
    "        num_actual_nodes = actual_node_feats.shape[0]\n",
    "        num_virtual_nodes = self.max_drug_nodes - num_actual_nodes\n",
    "        virtual_node_bit = torch.zeros([num_actual_nodes, 1])\n",
    "        # 填充原子数量，确保所有分子的特征中原子数统一为290\n",
    "        actual_node_feats = torch.cat((actual_node_feats, virtual_node_bit), 1)\n",
    "        v_d.ndata['h'] = actual_node_feats\n",
    "        # 更新真实和虚拟结点的特征，共75维度（最后一维是标志）\n",
    "        virtual_node_feat = torch.cat((torch.zeros(num_virtual_nodes, 74), torch.ones(num_virtual_nodes, 1)), 1)\n",
    "        v_d.add_nodes(num_virtual_nodes, {\"h\": virtual_node_feat})\n",
    "        # 添加自环并确保返回DGLGraph\n",
    "        v_d = dgl.add_self_loop(v_d)  # 使用dgl.add_self_loop而不是v_d.add_self_loop()\n",
    "    \n",
    "        # 验证返回的是DGLGraph对象\n",
    "        assert isinstance(v_d, dgl.DGLGraph), f\"图对象类型错误: {type(v_d)}\"\n",
    "\n",
    "        y = torch.tensor(self.df.iloc[index][\"Y\"], dtype=torch.float)\n",
    "        \n",
    "        v_p = self.df.iloc[index]['Protein']\n",
    "        # v_p = integer_label_protein(v_p)  不需要整数编码\n",
    "        \n",
    "        # encoding = self.tokenizer(\n",
    "        #     v_p,\n",
    "        #     add_special_tokens=True,\n",
    "        #     max_length=self.max_len,\n",
    "        #     padding='max_length',\n",
    "        #     truncation=True,\n",
    "        #     return_attention_mask=True,\n",
    "        #     return_tensors='pt'\n",
    "        # )\n",
    "\n",
    "        # 新的蛋白质序列处理方式\n",
    "        sequence_tokens = list(v_p)\n",
    "        valid_tokens = []\n",
    "        for token in sequence_tokens:\n",
    "            if token in self.tokenizer.vocab:\n",
    "                valid_tokens.append(token)\n",
    "            else:\n",
    "                valid_tokens.append(\"[UNK]\")\n",
    "        \n",
    "        sequence = \" \".join(valid_tokens)\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            sequence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        vp_ids = encoding['input_ids'].flatten()\n",
    "        vp_mask = encoding['attention_mask'].flatten()\n",
    "        return v_d, vp_ids, vp_mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from prettytable import PrettyTable\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, confusion_matrix, precision_recall_curve, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(pred_output, labels):\n",
    "    loss_fct = torch.nn.BCELoss()\n",
    "    m = nn.Sigmoid()\n",
    "    n = torch.squeeze(m(pred_output), 1)\n",
    "    loss = loss_fct(n, labels)\n",
    "    return n, loss\n",
    "\n",
    "def cross_entropy_logits(linear_output, label, weights=None):\n",
    "    class_output = F.log_softmax(linear_output, dim=1)\n",
    "    n = F.softmax(linear_output, dim=1)[:, 1]\n",
    "    max_class = class_output.max(1)\n",
    "    y_hat = max_class[1]  # get the index of the max log-probability\n",
    "    if weights is None:\n",
    "        loss = nn.NLLLoss()(class_output, label.type_as(y_hat).view(label.size(0)))\n",
    "    else:\n",
    "        losses = nn.NLLLoss(reduction=\"none\")(class_output, label.type_as(y_hat).view(label.size(0)))\n",
    "        loss = torch.sum(weights * losses) / torch.sum(weights)\n",
    "    return n, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# 获取当前时间并格式化为字符串，例如：'2024-11-05_14-30-00'\n",
    "current_time = datetime.now().strftime('%Y-%m-%d_%H-%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTITrainer(object):\n",
    "    def __init__(self, model, optim, device, num_epochs, train_dataloader, val_dataloader,\n",
    "                 batch_size, test_dataloader, outpit_dir, patience=20, min_delta=0.001):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.device = device\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.current_epoch = 0\n",
    "        self.step = 0\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.n_class = 1\n",
    "\n",
    "        self.best_model = None\n",
    "        self.best_epoch = None\n",
    "        self.best_auroc = 0\n",
    "\n",
    "        self.train_loss_epoch = []\n",
    "        self.train_model_loss_epoch = []\n",
    "        self.val_loss_epoch, self.val_auroc_epoch = [], []\n",
    "        self.test_metrics = {}\n",
    "        self.output_dir = outpit_dir\n",
    "        train_metric_header = [\"# Epoch\", \"Train_loss\"]\n",
    "        test_metric_header = [\"# Best Epoch\", \"AUROC\", \"AUPRC\", \"F1\", \"Sensitivity\", \"Specificity\", \"Accuracy\",\n",
    "                              \"Threshold\", \"Test_loss\"]\n",
    "        valid_metric_header = [\"# Epoch\", \"AUROC\", \"AUPRC\", \"Val_loss\"]\n",
    "        self.test_table = PrettyTable(test_metric_header)\n",
    "        self.train_table = PrettyTable(train_metric_header)\n",
    "        self.val_table = PrettyTable(valid_metric_header)\n",
    "\n",
    "         # 添加早停相关的属性\n",
    "        self.patience = patience  # 容忍多少个epoch验证集性能没有提升\n",
    "        self.min_delta = min_delta  # 最小提升幅度\n",
    "        self.counter = 0  # 计数器\n",
    "        self.best_loss = None  # 最佳验证集loss\n",
    "        self.early_stop = False  # 是否早停的标志\n",
    "\n",
    "    def train(self):\n",
    "        float2str = lambda x: '%0.4f' % x\n",
    "        for i in range(self.num_epochs):\n",
    "            self.current_epoch += 1\n",
    "            train_loss = self.train_epoch()\n",
    "            train_lst = [\"epoch \" + str(self.current_epoch)] + list(map(float2str, [train_loss]))\n",
    "            self.train_table.add_row(train_lst)\n",
    "            self.train_loss_epoch.append(train_loss)\n",
    "            auroc, auprc, val_loss = self.test(dataloader=\"val\")\n",
    "            val_lst = [\"epoch \" + str(self.current_epoch)] + list(map(float2str, [auroc, auprc, val_loss]))\n",
    "            self.val_table.add_row(val_lst)\n",
    "            self.val_loss_epoch.append(val_loss)\n",
    "            self.val_auroc_epoch.append(auroc)\n",
    "            if auroc >= self.best_auroc:\n",
    "                self.best_model = copy.deepcopy(self.model)\n",
    "                self.best_auroc = auroc\n",
    "                self.best_epoch = self.current_epoch\n",
    "                self.counter = 0  # 重置计数器\n",
    "            else:\n",
    "                self.counter += 1  # 增加计数器\n",
    "\n",
    "            # 早停检查\n",
    "            if self.counter >= self.patience:\n",
    "                print(f'Early stopping triggered after epoch {self.current_epoch}')\n",
    "                break\n",
    "            print('Validation at Epoch ' + str(self.current_epoch) + ' with validation loss ' + str(val_loss), \" AUROC \"\n",
    "                  + str(auroc) + \" AUPRC \" + str(auprc) + f\" | Early stopping counter: {self.counter}/{self.patience}\")\n",
    "        auroc, auprc, f1, sensitivity, specificity, accuracy, test_loss, thred_optim, precision = self.test(dataloader=\"test\")\n",
    "        test_lst = [\"epoch \" + str(self.best_epoch)] + list(map(float2str, [auroc, auprc, f1, sensitivity, specificity,\n",
    "                                                                            accuracy, thred_optim, test_loss]))\n",
    "        self.test_table.add_row(test_lst)\n",
    "        print('Test at Best Model of Epoch ' + str(self.best_epoch) + ' with test loss ' + str(test_loss), \" AUROC \"\n",
    "              + str(auroc) + \" AUPRC \" + str(auprc) + \" Sensitivity \" + str(sensitivity) + \" Specificity \" +\n",
    "              str(specificity) + \" Accuracy \" + str(accuracy) + \" Thred_optim \" + str(thred_optim))\n",
    "        self.test_metrics[\"auroc\"] = auroc\n",
    "        self.test_metrics[\"auprc\"] = auprc\n",
    "        self.test_metrics[\"test_loss\"] = test_loss\n",
    "        self.test_metrics[\"sensitivity\"] = sensitivity\n",
    "        self.test_metrics[\"specificity\"] = specificity\n",
    "        self.test_metrics[\"accuracy\"] = accuracy\n",
    "        self.test_metrics[\"thred_optim\"] = thred_optim\n",
    "        self.test_metrics[\"best_epoch\"] = self.best_epoch\n",
    "        self.test_metrics[\"F1\"] = f1\n",
    "        self.test_metrics[\"Precision\"] = precision\n",
    "        self.save_result()\n",
    "        return self.test_metrics\n",
    "    \n",
    "    def save_result(self):\n",
    "        torch.save(self.best_model.state_dict(),\n",
    "                os.path.join(self.output_dir, f\"best_model_epoch_{self.best_epoch}.pth\"))\n",
    "        torch.save(self.model.state_dict(), os.path.join(self.output_dir, f\"model_epoch_{self.current_epoch}.pth\"))\n",
    "        state = {\n",
    "            \"train_epoch_loss\": self.train_loss_epoch,\n",
    "            \"val_epoch_loss\": self.val_loss_epoch,\n",
    "            \"test_metrics\": self.test_metrics,\n",
    "        }\n",
    "        torch.save(state, os.path.join(self.output_dir, f\"result_metrics.pt\"))\n",
    "        val_prettytable_file = os.path.join(self.output_dir, \"valid_markdowntable.txt\")\n",
    "        test_prettytable_file = os.path.join(self.output_dir, \"test_markdowntable.txt\")\n",
    "        train_prettytable_file = os.path.join(self.output_dir, \"train_markdowntable.txt\")\n",
    "        with open(val_prettytable_file, 'w') as fp:\n",
    "            fp.write(self.val_table.get_string())\n",
    "        with open(test_prettytable_file, 'w') as fp:\n",
    "            fp.write(self.test_table.get_string())\n",
    "        with open(train_prettytable_file, \"w\") as fp:\n",
    "            fp.write(self.train_table.get_string())\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        loss_epoch = 0\n",
    "        num_batches = len(self.train_dataloader)\n",
    "        for i, (vd, vp_ids, vp_mask, y) in enumerate(tqdm(self.train_dataloader)):\n",
    "            self.step += 1\n",
    "            vd, vp_ids, vp_mask, labels = vd.to(self.device), vp_ids.to(self.device), vp_mask.to(self.device), y.float().to(self.device)\n",
    "            self.optim.zero_grad()\n",
    "            v_d, v_p, f, score = self.model(vd, vp_ids, vp_mask)\n",
    "            if self.n_class == 1:\n",
    "                n, loss = binary_cross_entropy(score, labels)\n",
    "            else:\n",
    "                n, loss = cross_entropy_logits(score, labels)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            loss_epoch += loss.item()\n",
    "        loss_epoch = loss_epoch / num_batches\n",
    "        print('Training at Epoch ' + str(self.current_epoch) + ' with training loss ' + str(loss_epoch))\n",
    "        return loss_epoch\n",
    "    \n",
    "    def test(self, dataloader=\"test\"):\n",
    "        test_loss = 0\n",
    "        y_label, y_pred = [], []\n",
    "        if dataloader == \"test\":\n",
    "            data_loader = self.test_dataloader\n",
    "        elif dataloader == \"val\":\n",
    "            data_loader = self.val_dataloader\n",
    "        else:\n",
    "            raise ValueError(f\"Error key value {dataloader}\")\n",
    "        num_batches = len(data_loader)\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for i, (vd, vp_ids, vp_mask, y) in enumerate(data_loader):\n",
    "                vd, vp_ids, vp_mask, labels = vd.to(self.device), vp_ids.to(self.device), vp_mask.to(self.device), y.float().to(self.device)\n",
    "                if dataloader == \"val\":\n",
    "                    v_d, v_p, f, score = self.model(vd, vp_ids, vp_mask)\n",
    "                elif dataloader == \"test\":\n",
    "                    v_d, v_p, f, score = self.best_model(vd, vp_ids, vp_mask)\n",
    "                if self.n_class == 1:\n",
    "                    n, loss = binary_cross_entropy(score, labels)\n",
    "                else:\n",
    "                    n, loss = cross_entropy_logits(score, labels)\n",
    "                test_loss += loss.item()\n",
    "                y_label = y_label + labels.to(\"cpu\").tolist()\n",
    "                y_pred = y_pred + n.to(\"cpu\").tolist()\n",
    "        auroc = roc_auc_score(y_label, y_pred)\n",
    "        auprc = average_precision_score(y_label, y_pred)\n",
    "        test_loss = test_loss / num_batches\n",
    "\n",
    "        if dataloader == \"test\":\n",
    "            fpr, tpr, thresholds = roc_curve(y_label, y_pred)\n",
    "            prec, recall, _ = precision_recall_curve(y_label, y_pred)\n",
    "            precision = tpr / (tpr + fpr)\n",
    "            f1 = 2 * precision * tpr / (tpr + precision + 0.00001)\n",
    "            thred_optim = thresholds[5:][np.argmax(f1[5:])]\n",
    "            y_pred_s = [1 if i else 0 for i in (y_pred >= thred_optim)]\n",
    "            cm1 = confusion_matrix(y_label, y_pred_s)\n",
    "            accuracy = (cm1[0, 0] + cm1[1, 1]) / sum(sum(cm1))\n",
    "            sensitivity = cm1[0, 0] / (cm1[0, 0] + cm1[0, 1])\n",
    "            specificity = cm1[1, 1] / (cm1[1, 0] + cm1[1, 1])\n",
    "            precision1 = precision_score(y_label, y_pred_s)\n",
    "            return auroc, auprc, np.max(f1[5:]), sensitivity, specificity, accuracy, test_loss, thred_optim, precision1\n",
    "        else:\n",
    "            return auroc, auprc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./prot_bert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, do_lower_case=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './dataset/Human'\n",
    "df_train = pd.read_csv(data_path+'/train.csv')\n",
    "df_val = pd.read_csv(data_path+'/val.csv')\n",
    "df_test = pd.read_csv(data_path+'/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_collate_func(x):\n",
    "    d, p_ids, p_mask, y = zip(*x)\n",
    "    # 确保图数据正确批处理，保留节点特征\n",
    "    batched_graph = dgl.batch(d)  # 这会保留图的ndata\n",
    "    return (\n",
    "        batched_graph,  # 这是一个DGLGraph对象，包含ndata['h']\n",
    "        torch.stack(p_ids),\n",
    "        torch.stack(p_mask),\n",
    "        torch.tensor(y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32\n",
    "num_epochs = 70\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DTIDataset(df_train.index.values, df_train)\n",
    "test_dataset = DTIDataset(df_test.index.values, df_test)\n",
    "val_dataset = DTIDataset(df_val.index.values, df_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, collate_fn=graph_collate_func)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, collate_fn=graph_collate_func)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, collate_fn=graph_collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图数据结构: Graph(num_nodes=290, num_edges=370,\n",
      "      ndata_schemes={'h': Scheme(shape=(75,), dtype=torch.float32)}\n",
      "      edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)})\n",
      "蛋白质序列编码: torch.Size([1024])\n",
      "注意力掩码: torch.Size([1024])\n",
      "标签值: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# 获取第一个样本\n",
    "sample = train_dataset[0]  # 返回(vd, vp_ids, vp_mask, y)\n",
    "\n",
    "# 解包查看具体内容\n",
    "vd, vp_ids, vp_mask, y = sample\n",
    "print(\"图数据结构:\", vd)\n",
    "print(\"蛋白质序列编码:\", vp_ids.shape)\n",
    "print(\"注意力掩码:\", vp_mask.shape)\n",
    "print(\"标签值:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DTIPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengdenggao/miniconda3/envs/dgl/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "model = DTIPredictor()\n",
    "model = model.to(device)\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "if torch.cuda.is_available():\n",
    "  torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 420,768,006\n",
      "Trainable parameters: 836,870\n",
      "Percentage of trainable parameters: 0.20%\n",
      "Frozen: embeddings.word_embeddings.weight\n",
      "Frozen: embeddings.position_embeddings.weight\n",
      "Frozen: embeddings.token_type_embeddings.weight\n",
      "Frozen: embeddings.LayerNorm.weight\n",
      "Frozen: embeddings.LayerNorm.bias\n",
      "Frozen: encoder.layer.0.attention.self.query.weight\n",
      "Frozen: encoder.layer.0.attention.self.query.bias\n",
      "Frozen: encoder.layer.0.attention.self.key.weight\n",
      "Frozen: encoder.layer.0.attention.self.key.bias\n",
      "Frozen: encoder.layer.0.attention.self.value.weight\n",
      "Frozen: encoder.layer.0.attention.self.value.bias\n",
      "Frozen: encoder.layer.0.attention.output.dense.weight\n",
      "Frozen: encoder.layer.0.attention.output.dense.bias\n",
      "Frozen: encoder.layer.0.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.0.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.0.intermediate.dense.weight\n",
      "Frozen: encoder.layer.0.intermediate.dense.bias\n",
      "Frozen: encoder.layer.0.output.dense.weight\n",
      "Frozen: encoder.layer.0.output.dense.bias\n",
      "Frozen: encoder.layer.0.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.0.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.1.attention.self.query.weight\n",
      "Frozen: encoder.layer.1.attention.self.query.bias\n",
      "Frozen: encoder.layer.1.attention.self.key.weight\n",
      "Frozen: encoder.layer.1.attention.self.key.bias\n",
      "Frozen: encoder.layer.1.attention.self.value.weight\n",
      "Frozen: encoder.layer.1.attention.self.value.bias\n",
      "Frozen: encoder.layer.1.attention.output.dense.weight\n",
      "Frozen: encoder.layer.1.attention.output.dense.bias\n",
      "Frozen: encoder.layer.1.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.1.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.1.intermediate.dense.weight\n",
      "Frozen: encoder.layer.1.intermediate.dense.bias\n",
      "Frozen: encoder.layer.1.output.dense.weight\n",
      "Frozen: encoder.layer.1.output.dense.bias\n",
      "Frozen: encoder.layer.1.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.1.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.2.attention.self.query.weight\n",
      "Frozen: encoder.layer.2.attention.self.query.bias\n",
      "Frozen: encoder.layer.2.attention.self.key.weight\n",
      "Frozen: encoder.layer.2.attention.self.key.bias\n",
      "Frozen: encoder.layer.2.attention.self.value.weight\n",
      "Frozen: encoder.layer.2.attention.self.value.bias\n",
      "Frozen: encoder.layer.2.attention.output.dense.weight\n",
      "Frozen: encoder.layer.2.attention.output.dense.bias\n",
      "Frozen: encoder.layer.2.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.2.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.2.intermediate.dense.weight\n",
      "Frozen: encoder.layer.2.intermediate.dense.bias\n",
      "Frozen: encoder.layer.2.output.dense.weight\n",
      "Frozen: encoder.layer.2.output.dense.bias\n",
      "Frozen: encoder.layer.2.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.2.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.3.attention.self.query.weight\n",
      "Frozen: encoder.layer.3.attention.self.query.bias\n",
      "Frozen: encoder.layer.3.attention.self.key.weight\n",
      "Frozen: encoder.layer.3.attention.self.key.bias\n",
      "Frozen: encoder.layer.3.attention.self.value.weight\n",
      "Frozen: encoder.layer.3.attention.self.value.bias\n",
      "Frozen: encoder.layer.3.attention.output.dense.weight\n",
      "Frozen: encoder.layer.3.attention.output.dense.bias\n",
      "Frozen: encoder.layer.3.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.3.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.3.intermediate.dense.weight\n",
      "Frozen: encoder.layer.3.intermediate.dense.bias\n",
      "Frozen: encoder.layer.3.output.dense.weight\n",
      "Frozen: encoder.layer.3.output.dense.bias\n",
      "Frozen: encoder.layer.3.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.3.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.4.attention.self.query.weight\n",
      "Frozen: encoder.layer.4.attention.self.query.bias\n",
      "Frozen: encoder.layer.4.attention.self.key.weight\n",
      "Frozen: encoder.layer.4.attention.self.key.bias\n",
      "Frozen: encoder.layer.4.attention.self.value.weight\n",
      "Frozen: encoder.layer.4.attention.self.value.bias\n",
      "Frozen: encoder.layer.4.attention.output.dense.weight\n",
      "Frozen: encoder.layer.4.attention.output.dense.bias\n",
      "Frozen: encoder.layer.4.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.4.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.4.intermediate.dense.weight\n",
      "Frozen: encoder.layer.4.intermediate.dense.bias\n",
      "Frozen: encoder.layer.4.output.dense.weight\n",
      "Frozen: encoder.layer.4.output.dense.bias\n",
      "Frozen: encoder.layer.4.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.4.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.5.attention.self.query.weight\n",
      "Frozen: encoder.layer.5.attention.self.query.bias\n",
      "Frozen: encoder.layer.5.attention.self.key.weight\n",
      "Frozen: encoder.layer.5.attention.self.key.bias\n",
      "Frozen: encoder.layer.5.attention.self.value.weight\n",
      "Frozen: encoder.layer.5.attention.self.value.bias\n",
      "Frozen: encoder.layer.5.attention.output.dense.weight\n",
      "Frozen: encoder.layer.5.attention.output.dense.bias\n",
      "Frozen: encoder.layer.5.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.5.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.5.intermediate.dense.weight\n",
      "Frozen: encoder.layer.5.intermediate.dense.bias\n",
      "Frozen: encoder.layer.5.output.dense.weight\n",
      "Frozen: encoder.layer.5.output.dense.bias\n",
      "Frozen: encoder.layer.5.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.5.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.6.attention.self.query.weight\n",
      "Frozen: encoder.layer.6.attention.self.query.bias\n",
      "Frozen: encoder.layer.6.attention.self.key.weight\n",
      "Frozen: encoder.layer.6.attention.self.key.bias\n",
      "Frozen: encoder.layer.6.attention.self.value.weight\n",
      "Frozen: encoder.layer.6.attention.self.value.bias\n",
      "Frozen: encoder.layer.6.attention.output.dense.weight\n",
      "Frozen: encoder.layer.6.attention.output.dense.bias\n",
      "Frozen: encoder.layer.6.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.6.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.6.intermediate.dense.weight\n",
      "Frozen: encoder.layer.6.intermediate.dense.bias\n",
      "Frozen: encoder.layer.6.output.dense.weight\n",
      "Frozen: encoder.layer.6.output.dense.bias\n",
      "Frozen: encoder.layer.6.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.6.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.7.attention.self.query.weight\n",
      "Frozen: encoder.layer.7.attention.self.query.bias\n",
      "Frozen: encoder.layer.7.attention.self.key.weight\n",
      "Frozen: encoder.layer.7.attention.self.key.bias\n",
      "Frozen: encoder.layer.7.attention.self.value.weight\n",
      "Frozen: encoder.layer.7.attention.self.value.bias\n",
      "Frozen: encoder.layer.7.attention.output.dense.weight\n",
      "Frozen: encoder.layer.7.attention.output.dense.bias\n",
      "Frozen: encoder.layer.7.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.7.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.7.intermediate.dense.weight\n",
      "Frozen: encoder.layer.7.intermediate.dense.bias\n",
      "Frozen: encoder.layer.7.output.dense.weight\n",
      "Frozen: encoder.layer.7.output.dense.bias\n",
      "Frozen: encoder.layer.7.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.7.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.8.attention.self.query.weight\n",
      "Frozen: encoder.layer.8.attention.self.query.bias\n",
      "Frozen: encoder.layer.8.attention.self.key.weight\n",
      "Frozen: encoder.layer.8.attention.self.key.bias\n",
      "Frozen: encoder.layer.8.attention.self.value.weight\n",
      "Frozen: encoder.layer.8.attention.self.value.bias\n",
      "Frozen: encoder.layer.8.attention.output.dense.weight\n",
      "Frozen: encoder.layer.8.attention.output.dense.bias\n",
      "Frozen: encoder.layer.8.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.8.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.8.intermediate.dense.weight\n",
      "Frozen: encoder.layer.8.intermediate.dense.bias\n",
      "Frozen: encoder.layer.8.output.dense.weight\n",
      "Frozen: encoder.layer.8.output.dense.bias\n",
      "Frozen: encoder.layer.8.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.8.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.9.attention.self.query.weight\n",
      "Frozen: encoder.layer.9.attention.self.query.bias\n",
      "Frozen: encoder.layer.9.attention.self.key.weight\n",
      "Frozen: encoder.layer.9.attention.self.key.bias\n",
      "Frozen: encoder.layer.9.attention.self.value.weight\n",
      "Frozen: encoder.layer.9.attention.self.value.bias\n",
      "Frozen: encoder.layer.9.attention.output.dense.weight\n",
      "Frozen: encoder.layer.9.attention.output.dense.bias\n",
      "Frozen: encoder.layer.9.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.9.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.9.intermediate.dense.weight\n",
      "Frozen: encoder.layer.9.intermediate.dense.bias\n",
      "Frozen: encoder.layer.9.output.dense.weight\n",
      "Frozen: encoder.layer.9.output.dense.bias\n",
      "Frozen: encoder.layer.9.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.9.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.10.attention.self.query.weight\n",
      "Frozen: encoder.layer.10.attention.self.query.bias\n",
      "Frozen: encoder.layer.10.attention.self.key.weight\n",
      "Frozen: encoder.layer.10.attention.self.key.bias\n",
      "Frozen: encoder.layer.10.attention.self.value.weight\n",
      "Frozen: encoder.layer.10.attention.self.value.bias\n",
      "Frozen: encoder.layer.10.attention.output.dense.weight\n",
      "Frozen: encoder.layer.10.attention.output.dense.bias\n",
      "Frozen: encoder.layer.10.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.10.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.10.intermediate.dense.weight\n",
      "Frozen: encoder.layer.10.intermediate.dense.bias\n",
      "Frozen: encoder.layer.10.output.dense.weight\n",
      "Frozen: encoder.layer.10.output.dense.bias\n",
      "Frozen: encoder.layer.10.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.10.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.11.attention.self.query.weight\n",
      "Frozen: encoder.layer.11.attention.self.query.bias\n",
      "Frozen: encoder.layer.11.attention.self.key.weight\n",
      "Frozen: encoder.layer.11.attention.self.key.bias\n",
      "Frozen: encoder.layer.11.attention.self.value.weight\n",
      "Frozen: encoder.layer.11.attention.self.value.bias\n",
      "Frozen: encoder.layer.11.attention.output.dense.weight\n",
      "Frozen: encoder.layer.11.attention.output.dense.bias\n",
      "Frozen: encoder.layer.11.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.11.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.11.intermediate.dense.weight\n",
      "Frozen: encoder.layer.11.intermediate.dense.bias\n",
      "Frozen: encoder.layer.11.output.dense.weight\n",
      "Frozen: encoder.layer.11.output.dense.bias\n",
      "Frozen: encoder.layer.11.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.11.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.12.attention.self.query.weight\n",
      "Frozen: encoder.layer.12.attention.self.query.bias\n",
      "Frozen: encoder.layer.12.attention.self.key.weight\n",
      "Frozen: encoder.layer.12.attention.self.key.bias\n",
      "Frozen: encoder.layer.12.attention.self.value.weight\n",
      "Frozen: encoder.layer.12.attention.self.value.bias\n",
      "Frozen: encoder.layer.12.attention.output.dense.weight\n",
      "Frozen: encoder.layer.12.attention.output.dense.bias\n",
      "Frozen: encoder.layer.12.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.12.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.12.intermediate.dense.weight\n",
      "Frozen: encoder.layer.12.intermediate.dense.bias\n",
      "Frozen: encoder.layer.12.output.dense.weight\n",
      "Frozen: encoder.layer.12.output.dense.bias\n",
      "Frozen: encoder.layer.12.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.12.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.13.attention.self.query.weight\n",
      "Frozen: encoder.layer.13.attention.self.query.bias\n",
      "Frozen: encoder.layer.13.attention.self.key.weight\n",
      "Frozen: encoder.layer.13.attention.self.key.bias\n",
      "Frozen: encoder.layer.13.attention.self.value.weight\n",
      "Frozen: encoder.layer.13.attention.self.value.bias\n",
      "Frozen: encoder.layer.13.attention.output.dense.weight\n",
      "Frozen: encoder.layer.13.attention.output.dense.bias\n",
      "Frozen: encoder.layer.13.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.13.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.13.intermediate.dense.weight\n",
      "Frozen: encoder.layer.13.intermediate.dense.bias\n",
      "Frozen: encoder.layer.13.output.dense.weight\n",
      "Frozen: encoder.layer.13.output.dense.bias\n",
      "Frozen: encoder.layer.13.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.13.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.14.attention.self.query.weight\n",
      "Frozen: encoder.layer.14.attention.self.query.bias\n",
      "Frozen: encoder.layer.14.attention.self.key.weight\n",
      "Frozen: encoder.layer.14.attention.self.key.bias\n",
      "Frozen: encoder.layer.14.attention.self.value.weight\n",
      "Frozen: encoder.layer.14.attention.self.value.bias\n",
      "Frozen: encoder.layer.14.attention.output.dense.weight\n",
      "Frozen: encoder.layer.14.attention.output.dense.bias\n",
      "Frozen: encoder.layer.14.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.14.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.14.intermediate.dense.weight\n",
      "Frozen: encoder.layer.14.intermediate.dense.bias\n",
      "Frozen: encoder.layer.14.output.dense.weight\n",
      "Frozen: encoder.layer.14.output.dense.bias\n",
      "Frozen: encoder.layer.14.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.14.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.15.attention.self.query.weight\n",
      "Frozen: encoder.layer.15.attention.self.query.bias\n",
      "Frozen: encoder.layer.15.attention.self.key.weight\n",
      "Frozen: encoder.layer.15.attention.self.key.bias\n",
      "Frozen: encoder.layer.15.attention.self.value.weight\n",
      "Frozen: encoder.layer.15.attention.self.value.bias\n",
      "Frozen: encoder.layer.15.attention.output.dense.weight\n",
      "Frozen: encoder.layer.15.attention.output.dense.bias\n",
      "Frozen: encoder.layer.15.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.15.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.15.intermediate.dense.weight\n",
      "Frozen: encoder.layer.15.intermediate.dense.bias\n",
      "Frozen: encoder.layer.15.output.dense.weight\n",
      "Frozen: encoder.layer.15.output.dense.bias\n",
      "Frozen: encoder.layer.15.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.15.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.16.attention.self.query.weight\n",
      "Frozen: encoder.layer.16.attention.self.query.bias\n",
      "Frozen: encoder.layer.16.attention.self.key.weight\n",
      "Frozen: encoder.layer.16.attention.self.key.bias\n",
      "Frozen: encoder.layer.16.attention.self.value.weight\n",
      "Frozen: encoder.layer.16.attention.self.value.bias\n",
      "Frozen: encoder.layer.16.attention.output.dense.weight\n",
      "Frozen: encoder.layer.16.attention.output.dense.bias\n",
      "Frozen: encoder.layer.16.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.16.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.16.intermediate.dense.weight\n",
      "Frozen: encoder.layer.16.intermediate.dense.bias\n",
      "Frozen: encoder.layer.16.output.dense.weight\n",
      "Frozen: encoder.layer.16.output.dense.bias\n",
      "Frozen: encoder.layer.16.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.16.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.17.attention.self.query.weight\n",
      "Frozen: encoder.layer.17.attention.self.query.bias\n",
      "Frozen: encoder.layer.17.attention.self.key.weight\n",
      "Frozen: encoder.layer.17.attention.self.key.bias\n",
      "Frozen: encoder.layer.17.attention.self.value.weight\n",
      "Frozen: encoder.layer.17.attention.self.value.bias\n",
      "Frozen: encoder.layer.17.attention.output.dense.weight\n",
      "Frozen: encoder.layer.17.attention.output.dense.bias\n",
      "Frozen: encoder.layer.17.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.17.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.17.intermediate.dense.weight\n",
      "Frozen: encoder.layer.17.intermediate.dense.bias\n",
      "Frozen: encoder.layer.17.output.dense.weight\n",
      "Frozen: encoder.layer.17.output.dense.bias\n",
      "Frozen: encoder.layer.17.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.17.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.18.attention.self.query.weight\n",
      "Frozen: encoder.layer.18.attention.self.query.bias\n",
      "Frozen: encoder.layer.18.attention.self.key.weight\n",
      "Frozen: encoder.layer.18.attention.self.key.bias\n",
      "Frozen: encoder.layer.18.attention.self.value.weight\n",
      "Frozen: encoder.layer.18.attention.self.value.bias\n",
      "Frozen: encoder.layer.18.attention.output.dense.weight\n",
      "Frozen: encoder.layer.18.attention.output.dense.bias\n",
      "Frozen: encoder.layer.18.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.18.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.18.intermediate.dense.weight\n",
      "Frozen: encoder.layer.18.intermediate.dense.bias\n",
      "Frozen: encoder.layer.18.output.dense.weight\n",
      "Frozen: encoder.layer.18.output.dense.bias\n",
      "Frozen: encoder.layer.18.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.18.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.19.attention.self.query.weight\n",
      "Frozen: encoder.layer.19.attention.self.query.bias\n",
      "Frozen: encoder.layer.19.attention.self.key.weight\n",
      "Frozen: encoder.layer.19.attention.self.key.bias\n",
      "Frozen: encoder.layer.19.attention.self.value.weight\n",
      "Frozen: encoder.layer.19.attention.self.value.bias\n",
      "Frozen: encoder.layer.19.attention.output.dense.weight\n",
      "Frozen: encoder.layer.19.attention.output.dense.bias\n",
      "Frozen: encoder.layer.19.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.19.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.19.intermediate.dense.weight\n",
      "Frozen: encoder.layer.19.intermediate.dense.bias\n",
      "Frozen: encoder.layer.19.output.dense.weight\n",
      "Frozen: encoder.layer.19.output.dense.bias\n",
      "Frozen: encoder.layer.19.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.19.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.20.attention.self.query.weight\n",
      "Frozen: encoder.layer.20.attention.self.query.bias\n",
      "Frozen: encoder.layer.20.attention.self.key.weight\n",
      "Frozen: encoder.layer.20.attention.self.key.bias\n",
      "Frozen: encoder.layer.20.attention.self.value.weight\n",
      "Frozen: encoder.layer.20.attention.self.value.bias\n",
      "Frozen: encoder.layer.20.attention.output.dense.weight\n",
      "Frozen: encoder.layer.20.attention.output.dense.bias\n",
      "Frozen: encoder.layer.20.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.20.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.20.intermediate.dense.weight\n",
      "Frozen: encoder.layer.20.intermediate.dense.bias\n",
      "Frozen: encoder.layer.20.output.dense.weight\n",
      "Frozen: encoder.layer.20.output.dense.bias\n",
      "Frozen: encoder.layer.20.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.20.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.21.attention.self.query.weight\n",
      "Frozen: encoder.layer.21.attention.self.query.bias\n",
      "Frozen: encoder.layer.21.attention.self.key.weight\n",
      "Frozen: encoder.layer.21.attention.self.key.bias\n",
      "Frozen: encoder.layer.21.attention.self.value.weight\n",
      "Frozen: encoder.layer.21.attention.self.value.bias\n",
      "Frozen: encoder.layer.21.attention.output.dense.weight\n",
      "Frozen: encoder.layer.21.attention.output.dense.bias\n",
      "Frozen: encoder.layer.21.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.21.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.21.intermediate.dense.weight\n",
      "Frozen: encoder.layer.21.intermediate.dense.bias\n",
      "Frozen: encoder.layer.21.output.dense.weight\n",
      "Frozen: encoder.layer.21.output.dense.bias\n",
      "Frozen: encoder.layer.21.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.21.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.22.attention.self.query.weight\n",
      "Frozen: encoder.layer.22.attention.self.query.bias\n",
      "Frozen: encoder.layer.22.attention.self.key.weight\n",
      "Frozen: encoder.layer.22.attention.self.key.bias\n",
      "Frozen: encoder.layer.22.attention.self.value.weight\n",
      "Frozen: encoder.layer.22.attention.self.value.bias\n",
      "Frozen: encoder.layer.22.attention.output.dense.weight\n",
      "Frozen: encoder.layer.22.attention.output.dense.bias\n",
      "Frozen: encoder.layer.22.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.22.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.22.intermediate.dense.weight\n",
      "Frozen: encoder.layer.22.intermediate.dense.bias\n",
      "Frozen: encoder.layer.22.output.dense.weight\n",
      "Frozen: encoder.layer.22.output.dense.bias\n",
      "Frozen: encoder.layer.22.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.22.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.23.attention.self.query.weight\n",
      "Frozen: encoder.layer.23.attention.self.query.bias\n",
      "Frozen: encoder.layer.23.attention.self.key.weight\n",
      "Frozen: encoder.layer.23.attention.self.key.bias\n",
      "Frozen: encoder.layer.23.attention.self.value.weight\n",
      "Frozen: encoder.layer.23.attention.self.value.bias\n",
      "Frozen: encoder.layer.23.attention.output.dense.weight\n",
      "Frozen: encoder.layer.23.attention.output.dense.bias\n",
      "Frozen: encoder.layer.23.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.23.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.23.intermediate.dense.weight\n",
      "Frozen: encoder.layer.23.intermediate.dense.bias\n",
      "Frozen: encoder.layer.23.output.dense.weight\n",
      "Frozen: encoder.layer.23.output.dense.bias\n",
      "Frozen: encoder.layer.23.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.23.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.24.attention.self.query.weight\n",
      "Frozen: encoder.layer.24.attention.self.query.bias\n",
      "Frozen: encoder.layer.24.attention.self.key.weight\n",
      "Frozen: encoder.layer.24.attention.self.key.bias\n",
      "Frozen: encoder.layer.24.attention.self.value.weight\n",
      "Frozen: encoder.layer.24.attention.self.value.bias\n",
      "Frozen: encoder.layer.24.attention.output.dense.weight\n",
      "Frozen: encoder.layer.24.attention.output.dense.bias\n",
      "Frozen: encoder.layer.24.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.24.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.24.intermediate.dense.weight\n",
      "Frozen: encoder.layer.24.intermediate.dense.bias\n",
      "Frozen: encoder.layer.24.output.dense.weight\n",
      "Frozen: encoder.layer.24.output.dense.bias\n",
      "Frozen: encoder.layer.24.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.24.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.25.attention.self.query.weight\n",
      "Frozen: encoder.layer.25.attention.self.query.bias\n",
      "Frozen: encoder.layer.25.attention.self.key.weight\n",
      "Frozen: encoder.layer.25.attention.self.key.bias\n",
      "Frozen: encoder.layer.25.attention.self.value.weight\n",
      "Frozen: encoder.layer.25.attention.self.value.bias\n",
      "Frozen: encoder.layer.25.attention.output.dense.weight\n",
      "Frozen: encoder.layer.25.attention.output.dense.bias\n",
      "Frozen: encoder.layer.25.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.25.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.25.intermediate.dense.weight\n",
      "Frozen: encoder.layer.25.intermediate.dense.bias\n",
      "Frozen: encoder.layer.25.output.dense.weight\n",
      "Frozen: encoder.layer.25.output.dense.bias\n",
      "Frozen: encoder.layer.25.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.25.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.26.attention.self.query.weight\n",
      "Frozen: encoder.layer.26.attention.self.query.bias\n",
      "Frozen: encoder.layer.26.attention.self.key.weight\n",
      "Frozen: encoder.layer.26.attention.self.key.bias\n",
      "Frozen: encoder.layer.26.attention.self.value.weight\n",
      "Frozen: encoder.layer.26.attention.self.value.bias\n",
      "Frozen: encoder.layer.26.attention.output.dense.weight\n",
      "Frozen: encoder.layer.26.attention.output.dense.bias\n",
      "Frozen: encoder.layer.26.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.26.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.26.intermediate.dense.weight\n",
      "Frozen: encoder.layer.26.intermediate.dense.bias\n",
      "Frozen: encoder.layer.26.output.dense.weight\n",
      "Frozen: encoder.layer.26.output.dense.bias\n",
      "Frozen: encoder.layer.26.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.26.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.27.attention.self.query.weight\n",
      "Frozen: encoder.layer.27.attention.self.query.bias\n",
      "Frozen: encoder.layer.27.attention.self.key.weight\n",
      "Frozen: encoder.layer.27.attention.self.key.bias\n",
      "Frozen: encoder.layer.27.attention.self.value.weight\n",
      "Frozen: encoder.layer.27.attention.self.value.bias\n",
      "Frozen: encoder.layer.27.attention.output.dense.weight\n",
      "Frozen: encoder.layer.27.attention.output.dense.bias\n",
      "Frozen: encoder.layer.27.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.27.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.27.intermediate.dense.weight\n",
      "Frozen: encoder.layer.27.intermediate.dense.bias\n",
      "Frozen: encoder.layer.27.output.dense.weight\n",
      "Frozen: encoder.layer.27.output.dense.bias\n",
      "Frozen: encoder.layer.27.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.27.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.28.attention.self.query.weight\n",
      "Frozen: encoder.layer.28.attention.self.query.bias\n",
      "Frozen: encoder.layer.28.attention.self.key.weight\n",
      "Frozen: encoder.layer.28.attention.self.key.bias\n",
      "Frozen: encoder.layer.28.attention.self.value.weight\n",
      "Frozen: encoder.layer.28.attention.self.value.bias\n",
      "Frozen: encoder.layer.28.attention.output.dense.weight\n",
      "Frozen: encoder.layer.28.attention.output.dense.bias\n",
      "Frozen: encoder.layer.28.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.28.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.28.intermediate.dense.weight\n",
      "Frozen: encoder.layer.28.intermediate.dense.bias\n",
      "Frozen: encoder.layer.28.output.dense.weight\n",
      "Frozen: encoder.layer.28.output.dense.bias\n",
      "Frozen: encoder.layer.28.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.28.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.29.attention.self.query.weight\n",
      "Frozen: encoder.layer.29.attention.self.query.bias\n",
      "Frozen: encoder.layer.29.attention.self.key.weight\n",
      "Frozen: encoder.layer.29.attention.self.key.bias\n",
      "Frozen: encoder.layer.29.attention.self.value.weight\n",
      "Frozen: encoder.layer.29.attention.self.value.bias\n",
      "Frozen: encoder.layer.29.attention.output.dense.weight\n",
      "Frozen: encoder.layer.29.attention.output.dense.bias\n",
      "Frozen: encoder.layer.29.attention.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.29.attention.output.LayerNorm.bias\n",
      "Frozen: encoder.layer.29.intermediate.dense.weight\n",
      "Frozen: encoder.layer.29.intermediate.dense.bias\n",
      "Frozen: encoder.layer.29.output.dense.weight\n",
      "Frozen: encoder.layer.29.output.dense.bias\n",
      "Frozen: encoder.layer.29.output.LayerNorm.weight\n",
      "Frozen: encoder.layer.29.output.LayerNorm.bias\n",
      "Frozen: pooler.dense.weight\n",
      "Frozen: pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "# 可训练参数\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')\n",
    "print(f'Percentage of trainable parameters: {100 * trainable_params / total_params:.2f}%')\n",
    "\n",
    "# BERT冻结层数\n",
    "for name, param in model.protein_extractor.bert.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Trainable: {name}\")\n",
    "    else:\n",
    "        print(f\"Frozen: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./result/experiment2024-11-15_22-27'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用格式化的时间字符串作为文件夹名\n",
    "folder_name = f'experiment{current_time}'\n",
    "\n",
    "# 确保文件夹存在，如果不存在则创建\n",
    "os.makedirs(os.path.join('./result', folder_name), exist_ok=True)\n",
    "\n",
    "output_dir = os.path.join('./result', folder_name)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DTITrainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    test_dataloader=test_loader,\n",
    "    batch_size=batch_size,\n",
    "    outpit_dir=output_dir,\n",
    "    optim=optimizer,  # 使用新的优化器\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"model_architecture.txt\"), \"w\") as wf:\n",
    "    wf.write(str(model))\n",
    "result = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DTIPredictor\n",
    "from tqdm import tqdm\n",
    "model = DTIPredictor()\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.load_state_dict(torch.load('result/experiment2024-11-14_11-40/best_model_epoch_47.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import os\n",
    "sdf_path = \"dataset/test/DGSY/sdf\"\n",
    "# 读取 SDF 文件\n",
    "mols = Chem.SDMolSupplier(os.path.join(sdf_path, '03_Oxypaeoniflorin.sdf'))\n",
    "\n",
    "# 为每个分子计算二维坐标\n",
    "for mol in mols:\n",
    "    if mol is not None:\n",
    "        tmp = AllChem.Compute2DCoords(mol)\n",
    "\n",
    "# 绘制并保存第一个分子的图像\n",
    "img = Draw.MolToImage(mols[0])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(v_d, v_p):\n",
    "    atom_featurizer = CanonicalAtomFeaturizer()\n",
    "    bond_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
    "    fc = partial(smiles_to_bigraph, add_self_loop=True)\n",
    "    tokenizer = BertTokenizer.from_pretrained('./prot_bert', do_lower_case=False)\n",
    "    max_drug_nodes = 290\n",
    "\n",
    "    v_d = fc(smiles=v_d, node_featurizer=atom_featurizer, edge_featurizer=bond_featurizer)\n",
    "    v_d = v_d.to(device)\n",
    "    actual_node_feats = v_d.ndata.pop('h').to(device)\n",
    "    num_actual_nodes = actual_node_feats.shape[0]\n",
    "    num_virtual_nodes = max_drug_nodes - num_actual_nodes\n",
    "    virtual_node_bit = torch.zeros([num_actual_nodes, 1]).to(device)\n",
    "    actual_node_feats = torch.cat((actual_node_feats, virtual_node_bit), 1).to(device)\n",
    "    v_d.ndata['h'] = actual_node_feats\n",
    "    virtual_node_feat = torch.cat(\n",
    "        (torch.zeros(num_virtual_nodes, 74).to(device), torch.ones(num_virtual_nodes, 1).to(device)), 1)\n",
    "    v_d.add_nodes(num_virtual_nodes, {\"h\": virtual_node_feat})\n",
    "    v_d = v_d.add_self_loop()\n",
    "    v_d = dgl.batch([v_d])\n",
    "\n",
    "    # 1. 将序列拆分成单个字符\n",
    "    sequence_tokens = list(v_p)\n",
    "    \n",
    "    # 2. 确保每个字符都在词汇表中\n",
    "    valid_tokens = []\n",
    "    for token in sequence_tokens:\n",
    "        if token in tokenizer.vocab:\n",
    "            valid_tokens.append(token)\n",
    "        else:\n",
    "            valid_tokens.append(\"[UNK]\")\n",
    "    \n",
    "    # 3. 重新组合序列\n",
    "    sequence = \" \".join(valid_tokens)\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        sequence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=1024,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # print(f\"Sequence length: {len(sequence_tokens)}\")\n",
    "    # print(f\"Valid tokens: {len(valid_tokens)}\")\n",
    "    # print(f\"First 10 encoded tokens: {encoding['input_ids'][0, :10]}\")\n",
    "    v_p_ids = encoding['input_ids'].to(device)  # 已经有batch维度，shape: [1, seq_len]\n",
    "    v_p_mask = encoding['attention_mask'].to(device)  # 已经有batch维度，shape: [1, seq_len]\n",
    "    outputs = model(v_d, v_p_ids, v_p_mask)\n",
    "    if isinstance(outputs, tuple) and len(outputs) == 4:\n",
    "        v_d, v_p, f, score = outputs\n",
    "        score = torch.clamp(score, min=-10, max=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 4 return values from test_model, got {outputs}\")\n",
    "    # print(\"origin score:\", score)\n",
    "    res_score = nn.Sigmoid()(score)\n",
    "    return res_score.cpu().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_path = \"dataset/test/DGSY\"\n",
    "    dataset_folder_path = \"csv\"\n",
    "    output_path = \"output\"\n",
    "    files_in_dataset_folder = os.listdir(os.path.join(test_path, dataset_folder_path))\n",
    "    count = 1\n",
    "    for file in files_in_dataset_folder:\n",
    "        file_path = os.path.join(test_path, dataset_folder_path, file)\n",
    "        file_out_path = os.path.join(test_path, output_path, file)\n",
    "        data_list = pd.read_csv(file_path)\n",
    "        smiles_list = data_list.iloc[:,0]\n",
    "        sequences_list = data_list.iloc[:,1]\n",
    "        res_score = []\n",
    "        res_smile = []\n",
    "        res_seq = []\n",
    "\n",
    "        for i in tqdm(range(len(data_list))):\n",
    "            score = get_score(smiles_list[i], sequences_list[i])\n",
    "            # print(\"score: \", score)\n",
    "            res_score.append(float(score)) \n",
    "            res_smile.append(smiles_list[i])\n",
    "            res_seq.append(sequences_list[i])\n",
    "        \n",
    "        result = pd.DataFrame({\"smiles\": res_smile, \"sequence\": res_seq, \"score\": res_score})\n",
    "        result.to_csv(file_out_path, index=False)\n",
    "        print(f'{count} completed, {len(files_in_dataset_folder) - count} remains')\n",
    "        count = count + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'dataset/test/DGSY/output'\n",
    "top_dir_90 = 'output\\Top0.9'\n",
    "result_list = os.listdir(result_dir)\n",
    "for result in result_list:\n",
    "    df = pd.read_csv(os.path.join(result_dir, result))\n",
    "    df_sorted = df[df['score'] > 0.90]\n",
    "    df_sorted = df_sorted.sort_values(by=\"score\", ascending=False)\n",
    "    if not os.path.exists(top_dir_90):\n",
    "        os.mkdir(top_dir_90)\n",
    "    df_sorted.to_csv(os.path.join(top_dir_90, result), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
